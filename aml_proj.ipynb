{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1yirBwNnP-IEkZ4KO-8LdtJLqNGPZcDjc",
      "authorship_tag": "ABX9TyOSK15q4C3yqJ7Jh6jrBRwE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cemdaloglu/AML_project/blob/main/aml_proj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import random_split\n",
        "import time\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, accuracy_score\n",
        "from pathlib import Path\n",
        "import time\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "5f8bNThWsuMU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_prepare(train_set_path: str, test_set_path: str, train_label_path: str, test_label_path: str,\n",
        "                    patch_size: np.array) -> list:\n",
        "    train_set = []\n",
        "    for image_path in glob.glob(f\"{train_set_path}/*.npy\"):\n",
        "        train_set.append(np.load(image_path))\n",
        "\n",
        "    label_set = []\n",
        "    for image_path in glob.glob(f\"{train_label_path}/*.npy\"):\n",
        "        label_set.append(np.load(image_path))\n",
        "\n",
        "    test_set = []\n",
        "    for image_path in glob.glob(f\"{test_set_path}/*.npy\"):\n",
        "        test_set.append(np.load(image_path))\n",
        "\n",
        "    test_label_set = []\n",
        "    for image_path in glob.glob(f\"{test_label_path}/*.npy\"):\n",
        "        test_label_set.append(np.load(image_path))\n",
        "\n",
        "    train_set = np.reshape(train_set, (-1, 4, patch_size[0], patch_size[1]))\n",
        "    label_set = np.reshape(label_set, (-1, patch_size[0], patch_size[1]))\n",
        "    test_set = np.reshape(test_set, (-1, 4, patch_size[0], patch_size[1]))\n",
        "    test_label_set = np.reshape(test_label_set, (-1, patch_size[0], patch_size[1]))\n",
        "\n",
        "    return list(zip(train_set, label_set)), list(zip(test_set, test_label_set))"
      ],
      "metadata": {
        "id": "0lKBHHaIjhyZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fMZhLpXVsBqQ"
      },
      "outputs": [],
      "source": [
        "def get_dataloaders(train_dataset, val_dataset, dataloader_workers: int = 3, batch_size: int = 8):\n",
        "    \"\"\"\n",
        "    Get Dataloaders for the given dataset.\n",
        "    \n",
        "    @param dataset The dataset to wrap into a Dataloader\n",
        "    @param dataloader_workers How many workers to give each Dataloader.\n",
        "    @param batch_size Batch Size\n",
        "    \"\"\"\n",
        "\n",
        "    kwargs = {'pin_memory': True, 'num_workers': dataloader_workers}\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "        **kwargs\n",
        "    )\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        drop_last=True,\n",
        "        shuffle=True,\n",
        "        **kwargs\n",
        "    )\n",
        "    return {\n",
        "        'train': train_loader,\n",
        "        'val': val_loader\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_test_dataloaders(test_dataset, dataloader_workers: int = 3, batch_size: int = 8):\n",
        "    \"\"\"\n",
        "    Get Dataloaders for the given dataset.\n",
        "\n",
        "    @param test_dataset The dataset to wrap into a Dataloader\n",
        "    @param dataloader_workers How many workers to give each Dataloader.\n",
        "    @param batch_size Batch Size\n",
        "    \"\"\"\n",
        "\n",
        "    kwargs = {'pin_memory': True, 'num_workers': dataloader_workers}\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "        **kwargs\n",
        "    )\n",
        "    return test_loader"
      ],
      "metadata": {
        "id": "FuCon8m2j0Vz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding='same'),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding='same'),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)"
      ],
      "metadata": {
        "id": "UabXpNVBs0OR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DownBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DownBlock, self).__init__()\n",
        "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
        "        self.down_sample = nn.MaxPool2d(2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_out = self.double_conv(x)\n",
        "        down_out = self.down_sample(skip_out)\n",
        "        return down_out, skip_out"
      ],
      "metadata": {
        "id": "IR5I_govs6LO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UpBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UpBlock, self).__init__()\n",
        "        self.up_sample = nn.ConvTranspose2d(in_channels - out_channels, in_channels - out_channels, kernel_size=2,\n",
        "                                            stride=2)\n",
        "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, down_input, skip_input):\n",
        "        x = self.up_sample(down_input)\n",
        "        x = torch.cat([x, skip_input], dim=1)\n",
        "        return self.double_conv(x)"
      ],
      "metadata": {
        "id": "z66sw3dWs8Oc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, out_classes=5):\n",
        "        super(UNet, self).__init__()\n",
        "        # Downsampling Path\n",
        "        self.down_conv1 = DownBlock(4, 64)\n",
        "        self.down_conv2 = DownBlock(64, 128)\n",
        "        self.down_conv3 = DownBlock(128, 256)\n",
        "        self.down_conv4 = DownBlock(256, 512)\n",
        "        # Bottleneck\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.double_conv = DoubleConv(512, 1024)\n",
        "        # Upsampling Path\n",
        "        self.up_conv4 = UpBlock(512 + 1024, 512)\n",
        "        self.up_conv3 = UpBlock(256 + 512, 256)\n",
        "        self.up_conv2 = UpBlock(128 + 256, 128)\n",
        "        self.up_conv1 = UpBlock(128 + 64, 64)\n",
        "        # Final Convolution\n",
        "        self.conv_last = nn.Conv2d(64, out_classes, kernel_size=1)\n",
        "        self.m = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, skip1_out = self.down_conv1(x)\n",
        "        x, skip2_out = self.down_conv2(x)\n",
        "        x, skip3_out = self.down_conv3(x)\n",
        "        x, skip4_out = self.down_conv4(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.double_conv(x)\n",
        "        x = self.up_conv4(x, skip4_out)\n",
        "        x = self.up_conv3(x, skip3_out)\n",
        "        x = self.up_conv2(x, skip2_out)\n",
        "        x = self.up_conv1(x, skip1_out)\n",
        "        x = self.conv_last(x)\n",
        "        x = self.m(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "gU8miKOOs-ae"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss(target, pred, criterion, metrics):\n",
        "    '''\n",
        "    TODO: THINK ABOUT NICE LOSS AND ALSO WEIGHTS\n",
        "    '''\n",
        "    if criterion == \"CEL\":\n",
        "        loss = nn.CrossEntropyLoss()\n",
        "    elif criterion == \"wCEL\":\n",
        "        loss = nn.CrossEntropyLoss() # TODO\n",
        "    else:\n",
        "        loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    loss = loss(target, pred)\n",
        "    if metrics is not None:\n",
        "        metrics['loss'] += loss.data.cpu().numpy() * target.size(0) # TODO probably add f1 stuff\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "7rvfGN4GkXB7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloaders, use_cuda, optimizer, num_epochs, checkpoint_path_model, loss_criterion: str,\n",
        "                trained_epochs: int = 0):\n",
        "    best_loss = 1e10\n",
        "    total_acc = {key: [] for key in ['train', 'val']}\n",
        "    total_loss = {key: [] for key in ['train', 'val']}\n",
        "\n",
        "    # iterate over all epochs\n",
        "    for epoch in range(trained_epochs, num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        since = time.time()\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            metrics = defaultdict(float)\n",
        "            epoch_samples = 0\n",
        "\n",
        "            for dic in dataloaders[phase]:\n",
        "                inputs, labels = dic['image'], dic['mask']\n",
        "\n",
        "                if use_cuda:\n",
        "                    inputs = inputs.to('cuda', dtype=torch.float)  # [batch_size, in_channels, H, W]\n",
        "                    labels = labels.to('cuda', dtype=torch.long)\n",
        "\n",
        "                optimizer.zero_grad()  # zero the parameter gradients\n",
        "\n",
        "                epoch_accuracy = 0\n",
        "                epoch_loss = 0\n",
        "                # forward pass: compute prediction and the loss btw prediction and true label\n",
        "                # track history only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "\n",
        "                    # output is probability [batch size, n_classes, H, W], target is class [batch size, H, W]\n",
        "                    # TODO: decide on loss!! (dummy function here)\n",
        "                    loss = calc_loss(outputs, labels, loss_criterion, metrics)\n",
        "\n",
        "                    # backward + optimize only if in training phase (no need for torch.no_grad in this training pass)\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                    epoch_loss += loss\n",
        "\n",
        "                # statistics\n",
        "                epoch_samples += inputs.size(0)\n",
        "\n",
        "                acc = ((outputs.argmax(dim=1) == labels).float().mean())\n",
        "                epoch_accuracy += acc / len(dataloaders[phase])\n",
        "                epoch_loss += loss / len(dataloaders[phase])\n",
        "            total_acc[phase].append(epoch_accuracy)\n",
        "            total_loss[phase].append(epoch_loss)\n",
        "\n",
        "            epoch_loss = loss / epoch_samples\n",
        "            print(\"epoch_loss = \", epoch_loss)\n",
        "\n",
        "            # save the model weights in validation phase \n",
        "            if phase == 'val':\n",
        "                if epoch_loss < best_loss:\n",
        "                    print(f\"saving best model to {checkpoint_path_model}\")\n",
        "                    best_loss = epoch_loss\n",
        "                    torch.save(model.state_dict(), checkpoint_path_model)\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    print('Best val loss: {:4f}'.format(best_loss))\n",
        "\n",
        "    plt.plot(total_loss['train'], color='blue')\n",
        "    plt.plot(total_loss['val'], color='orange')\n",
        "    plt.title(\"Loss\")\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['train_loss', 'valid_loss'])\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(total_acc['train'], color='blue')\n",
        "    plt.plot(total_acc['val'], color='orange')\n",
        "    plt.title(\"Accuracy\")\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.legend(['train_acc', 'val_acc'])\n",
        "    plt.show()\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(torch.load(checkpoint_path_model))\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "qs9uL-5Wsdgt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_project_root() -> Path:\n",
        "    \"\"\" return path to the project root\"\"\"\n",
        "    return Path(__file__).parent\n",
        "\n",
        "\n",
        "def test(model, test_loader, use_cuda: bool, loss_criterion=None, n_classes = 5):\n",
        "    \"\"\"\n",
        "    Compute test metrics on test data set \n",
        "\n",
        "    @param model: -- the neural network\n",
        "    @param: use_cuda: -- true if GPU should be used\n",
        "    @param: loss_fun: -- the used loss function from calc_loss\n",
        "    @param: test_loader: -- test data dataloader\n",
        "    @param: test_batch_size: -- used batch size\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    labels = np.arange(n_classes)\n",
        "    conf_matrix = np.zeros((n_classes, n_classes))\n",
        "\n",
        "    # initialize all variables \n",
        "    num_correct = 0\n",
        "    num_pixels = 0\n",
        "    all_images = []\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "    test_losses = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        acc = 0\n",
        "        pre = 0\n",
        "        recall = 0\n",
        "        f1 = 0\n",
        "        for batch_index, dic in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "            images, labels = dic['image'], dic['mask']\n",
        "\n",
        "            all_images.extend(images.cpu())\n",
        "            all_labels.extend(labels.cpu())\n",
        "\n",
        "            if use_cuda:\n",
        "                images = images.to('cuda', dtype=torch.float)\n",
        "                labels = labels.to('cuda', dtype=torch.float)\n",
        "\n",
        "            # run network\n",
        "            prediction = model(images)  # torch.Size([batch_size, n_classes, h, w])\n",
        "\n",
        "            # compute and save loss\n",
        "            test_loss = calc_loss(prediction, labels.long(), criterion=loss_criterion)\n",
        "            test_losses.extend(test_loss.cpu().numpy().reshape(-1))\n",
        "\n",
        "            # take argmax to get class \n",
        "            final_prediction = torch.argmax(prediction.softmax(dim=1), dim=1)  # torch.Size([batch_size, h, w])\n",
        "\n",
        "            for j in range(len(labels)):\n",
        "                true_label = labels[j].cpu().detach().numpy().flatten()\n",
        "                pred_label = final_prediction[j].cpu().detach().numpy().flatten()\n",
        "                conf_matrix += confusion_matrix(true_label, pred_label,\n",
        "                                                labels=labels)  # TODO: maybe use to compute IoU (Intersection over Union)\n",
        "\n",
        "            all_predictions.extend(final_prediction.cpu())\n",
        "\n",
        "            # Compute number of correct predictions \n",
        "            num_correct += (final_prediction == labels).sum()\n",
        "            num_pixels += torch.numel(final_prediction)\n",
        "\n",
        "            #   calculate accuracy\n",
        "            acc += accuracy_score(true_label, pred_label) / len(test_loader)\n",
        "            #   calculate precision\n",
        "            pre += precision_score(true_label, pred_label, average='macro', zero_division=1) / len(test_loader)\n",
        "            #   calculate recall\n",
        "            recall += recall_score(true_label, pred_label, average='macro', zero_division=1) / len(test_loader)\n",
        "            #   calculate F1 score\n",
        "            f1 += f1_score(true_label, pred_label, average='macro') / len(test_loader)\n",
        "    print('Loss of best validation batch:', np.min(test_losses))\n",
        "\n",
        "    losses_per_instance = pd.DataFrame(data={'loss': test_losses})\n",
        "\n",
        "    # print metrics\n",
        "    print(\"Mean Loss:\", np.mean(test_losses), \"\\nMean Acc:\", acc, \"\\nMean Macro Precision:\", pre,\n",
        "          \"\\nMean Macro Recall:\", recall,\n",
        "          \"\\nMean Macro F1 Score:\", f1)\n",
        "\n",
        "    # plot confusion matrix\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(conf_matrix)\n",
        "    # We want to show all ticks...\n",
        "    ax.set_xticks(np.arange(n_classes))\n",
        "    ax.set_yticks(np.arange(n_classes))\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    test_accuracy = (num_correct / num_pixels * 100).cpu().numpy()\n",
        "    print(f\"Got {num_correct}/{num_pixels} with acc {test_accuracy}\")\n",
        "\n",
        "\n",
        "def test_model(test_loader, criterion):\n",
        "    best_path = 'best_unet.pth'\n",
        "    model = torch.load(best_path)\n",
        "\n",
        "    # evaluate on test set\n",
        "    model = model.eval()\n",
        "\n",
        "    test_loss_arr = []\n",
        "    with torch.no_grad():\n",
        "        epoch_test_loss = 0\n",
        "        acc = 0\n",
        "        pre = 0\n",
        "        recall = 0\n",
        "        f1 = 0\n",
        "        conf_matrix = np.zeros((5, 5))\n",
        "        #   iterate over test batches\n",
        "        for loaded_data in test_loader:\n",
        "            input_data, label = loaded_data\n",
        "            input_data = input_data.to('cuda', dtype=torch.float32)\n",
        "            label = label.to('cuda', dtype=torch.long)\n",
        "\n",
        "            test_output = model(input_data.float())\n",
        "            test_loss = criterion(test_output, label)\n",
        "\n",
        "            epoch_test_loss += test_loss / len(test_loader)\n",
        "            test_output = (test_output.argmax(dim=1)).long()\n",
        "            label = np.array(label.cpu())\n",
        "            test_output = np.array(test_output.cpu())\n",
        "            #   get confusion matrix\n",
        "            if (confusion_matrix(label, test_output).shape == (5, 5)):\n",
        "                conf_matrix += confusion_matrix(label, test_output) / len(test_loader)\n",
        "            #         conf_matrix.append(confusion_matrix(label, test_output))\n",
        "            #   calculate accuracy\n",
        "            acc += accuracy_score(label, test_output) / len(test_loader)\n",
        "            #   calculate precision\n",
        "            pre += precision_score(label, test_output, average='macro', zero_division=1) / len(test_loader)\n",
        "            #   calculate recall\n",
        "            recall += recall_score(label, test_output, average='macro', zero_division=1) / len(test_loader)\n",
        "            #   calculate F1 score\n",
        "            f1 += f1_score(label, test_output, average='macro') / len(test_loader)\n",
        "\n",
        "    test_loss_arr.append(epoch_test_loss)\n",
        "    test_loss_arr = np.array(test_loss_arr, dtype='float')\n",
        "    losses = np.mean(test_loss_arr)\n",
        "\n",
        "    # print metrics\n",
        "    print(\"Mean Loss:\", losses, \"\\nMean Acc:\", acc, \"\\nMean Macro Precision:\", pre, \"\\nMean Macro Recall:\", recall,\n",
        "          \"\\nMean Macro F1 Score:\", f1)\n",
        "\n",
        "    # plot confusion matrix\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(conf_matrix)\n",
        "    # We want to show all ticks...\n",
        "    ax.set_xticks(np.arange(5))\n",
        "    ax.set_yticks(np.arange(5))\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "SYfk4sPwkBO0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from matplotlib.transforms import Transform\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from skimage.io import imread\n",
        "import glob\n",
        "\n",
        "class CityData(Dataset):\n",
        "\n",
        "    def __init__(self, train_test_path, transforms = None):\n",
        "        \"\"\"\n",
        "        train_test_path -- path to either \"train\", \"val\", or \"test\" containing subfolders 'images' and 'masks' where the patched data lies, e.g. ../patches/train\n",
        "        transform -- transform (from torchvision.transforms) to be applied to the data\n",
        "\n",
        "        Usage: citydata = CityData(train_test_path)\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Define Dataset \n",
        "        self.patch_imgs_path = sorted(glob.glob(train_test_path + 'images/*'))\n",
        "        self.patch_masks_path = sorted(glob.glob(train_test_path + 'masks/*'))\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        return the number of total samples contained in the dataset\n",
        "        \"\"\"\n",
        "        return len(self.patch_imgs_path)\n",
        "\n",
        "    def __getitem__(self, idx): \n",
        "        \"\"\" \n",
        "        Return the examples at index [idx]. The example is a dict with keys \n",
        "        - 'images' value: Tensor for an RGB image of shape \n",
        "        - 'mask' value: ground truth labels 0,..., n_classes of shape\n",
        "        - 'img_idx' value: index of sample\n",
        "        \"\"\"\n",
        "\n",
        "        image = imread(self.patch_imgs_path[idx])\n",
        "        mask = imread(self.patch_masks_path[idx])\n",
        "        \n",
        "        # To tensor \n",
        "        image = torch.from_numpy(image) \n",
        "        mask = torch.from_numpy(mask)    \n",
        "\n",
        "        #preprocessed image, for input into NN\n",
        "        sample = {'image':image, 'mask':mask, 'img_idx':idx}\n",
        "\n",
        "        if self.transforms:\n",
        "            sample = self.transforms(sample)\n",
        "\n",
        "        return sample"
      ],
      "metadata": {
        "id": "XBbZJ6SFn75j"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = CityData(\"/content/drive/MyDrive/patches_new/patches/train/\") \n",
        "val_set = CityData(\"/content/drive/MyDrive/patches_new/patches/val/\") \n",
        "test_set = CityData(\"/content/drive/MyDrive/patches_new/patches/test/\") "
      ],
      "metadata": {
        "id": "pffAQw6NsV8j"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_set.__len__(), val_set.__len__(), test_set.__len__())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exXXlK0dsW1P",
        "outputId": "fa4419ce-9c8d-4f48-d1a1-7d87173ba8ea"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10123 0 3696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick your hyper parameters\n",
        "epoch_count = 3\n",
        "train_val_batch = 64\n",
        "test_batch = 64\n",
        "learning_rate = 0.01\n",
        "weight_decay = 0.001\n",
        "\n",
        "train_set = CityData(\"/content/drive/MyDrive/patches_new/patches/train/\") \n",
        "val_set = CityData(\"/content/drive/MyDrive/patches_new/patches/val/\") \n",
        "test_set = CityData(\"/content/drive/MyDrive/patches_new/patches/test/\") \n",
        "\n",
        "data_loaders = get_dataloaders(train_set, test_set, batch_size=train_val_batch)\n",
        "\n",
        "#test_loader = get_test_dataloaders(test_dataset=test_set, batch_size=test_batch)\n",
        "\n",
        "# initialize your network\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = UNet()\n",
        "model = model.to(device)\n",
        "#summary(model, input_size=(4, 64, 64))\n",
        "\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "trained_model = train_model(model=model, dataloaders=data_loaders, use_cuda=True, optimizer=optimizer,\n",
        "                            num_epochs=epoch_count, loss_criterion=\"CEL\", checkpoint_path_model=\"best_unet.pth\")\n",
        "\n",
        "#test(model=trained_model, use_cuda=True, test_loader=test_loader, n_classes=5, loss_criterion=\"CEL\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kcwVdiQpj5fg",
        "outputId": "43493fd4-4c20-4c8f-fe4e-8196f6b43446"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/3\n",
            "----------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-2474beeb4e11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m trained_model = train_model(model=model, dataloaders=data_loaders, use_cuda=True, optimizer=optimizer,\n\u001b[0;32m---> 26\u001b[0;31m                             num_epochs=epoch_count, loss_criterion=\"CEL\", checkpoint_path_model=\"best_unet.pth\")\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#test(model=trained_model, use_cuda=True, test_loader=test_loader, n_classes=5, loss_criterion=\"CEL\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-4f03a7c9787f>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, use_cuda, optimizer, num_epochs, checkpoint_path_model, loss_criterion, trained_epochs)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mepoch_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-14-09d5ad6c3e33>\", line 42, in __getitem__\n    image = imread(self.patch_imgs_path[idx])\n  File \"/usr/local/lib/python3.7/dist-packages/skimage/io/_io.py\", line 48, in imread\n    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n  File \"/usr/local/lib/python3.7/dist-packages/skimage/io/manage_plugins.py\", line 207, in call_plugin\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/skimage/io/_plugins/imageio_plugin.py\", line 10, in imread\n    return np.asarray(imageio_imread(*args, **kwargs))\n  File \"/usr/local/lib/python3.7/dist-packages/imageio/core/functions.py\", line 265, in imread\n    reader = read(uri, format, \"i\", **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/imageio/core/functions.py\", line 182, in get_reader\n    \"Could not find a format to read the specified file in %s mode\" % modename\nValueError: Could not find a format to read the specified file in single-image mode\n"
          ]
        }
      ]
    }
  ]
}