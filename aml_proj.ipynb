{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1yirBwNnP-IEkZ4KO-8LdtJLqNGPZcDjc",
      "authorship_tag": "ABX9TyMVqaRfxEK5j0CkNwFF+JM0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cemdaloglu/AML_project/blob/main/aml_proj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import random_split\n",
        "import time\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, accuracy_score\n",
        "from pathlib import Path\n",
        "import time\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "5f8bNThWsuMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMZhLpXVsBqQ"
      },
      "outputs": [],
      "source": [
        "def get_dataloaders(train_dataset, val_dataset, dataloader_workers: int = 3, batch_size: int = 8):\n",
        "    \"\"\"\n",
        "    Get Dataloaders for the given dataset.\n",
        "    \n",
        "    @param dataset The dataset to wrap into a Dataloader\n",
        "    @param dataloader_workers How many workers to give each Dataloader.\n",
        "    @param batch_size Batch Size\n",
        "    \"\"\"\n",
        "\n",
        "    kwargs = {'pin_memory': True, 'num_workers': dataloader_workers}\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "        **kwargs\n",
        "    )\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        drop_last=True,\n",
        "        shuffle=True,\n",
        "        **kwargs\n",
        "    )\n",
        "    return {\n",
        "        'train': train_loader,\n",
        "        'val': val_loader\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_test_dataloaders(test_dataset, dataloader_workers: int = 3, batch_size: int = 8):\n",
        "    \"\"\"\n",
        "    Get Dataloaders for the given dataset.\n",
        "\n",
        "    @param test_dataset The dataset to wrap into a Dataloader\n",
        "    @param dataloader_workers How many workers to give each Dataloader.\n",
        "    @param batch_size Batch Size\n",
        "    \"\"\"\n",
        "\n",
        "    kwargs = {'pin_memory': True, 'num_workers': dataloader_workers}\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "        **kwargs\n",
        "    )\n",
        "    return test_loader"
      ],
      "metadata": {
        "id": "FuCon8m2j0Vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding='same'),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding='same'),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)"
      ],
      "metadata": {
        "id": "UabXpNVBs0OR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DownBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DownBlock, self).__init__()\n",
        "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
        "        self.down_sample = nn.MaxPool2d(2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_out = self.double_conv(x)\n",
        "        down_out = self.down_sample(skip_out)\n",
        "        return down_out, skip_out"
      ],
      "metadata": {
        "id": "IR5I_govs6LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UpBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UpBlock, self).__init__()\n",
        "        self.up_sample = nn.ConvTranspose2d(in_channels - out_channels, in_channels - out_channels, kernel_size=2,\n",
        "                                            stride=2)\n",
        "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, down_input, skip_input):\n",
        "        x = self.up_sample(down_input)\n",
        "        x = torch.cat([x, skip_input], dim=1)\n",
        "        return self.double_conv(x)"
      ],
      "metadata": {
        "id": "z66sw3dWs8Oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, out_classes=6):\n",
        "        super(UNet, self).__init__()\n",
        "        # Downsampling Path\n",
        "        self.down_conv1 = DownBlock(4, 64)\n",
        "        self.down_conv2 = DownBlock(64, 128)\n",
        "        self.down_conv3 = DownBlock(128, 256)\n",
        "        self.down_conv4 = DownBlock(256, 512)\n",
        "        # Bottleneck\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.double_conv = DoubleConv(512, 1024)\n",
        "        # Upsampling Path\n",
        "        self.up_conv4 = UpBlock(512 + 1024, 512)\n",
        "        self.up_conv3 = UpBlock(256 + 512, 256)\n",
        "        self.up_conv2 = UpBlock(128 + 256, 128)\n",
        "        self.up_conv1 = UpBlock(128 + 64, 64)\n",
        "        # Final Convolution\n",
        "        self.conv_last = nn.Conv2d(64, out_classes, kernel_size=1)\n",
        "        self.m = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, skip1_out = self.down_conv1(x)\n",
        "        x, skip2_out = self.down_conv2(x)\n",
        "        x, skip3_out = self.down_conv3(x)\n",
        "        x, skip4_out = self.down_conv4(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.double_conv(x)\n",
        "        x = self.up_conv4(x, skip4_out)\n",
        "        x = self.up_conv3(x, skip3_out)\n",
        "        x = self.up_conv2(x, skip2_out)\n",
        "        x = self.up_conv1(x, skip1_out)\n",
        "        x = self.conv_last(x)\n",
        "        x = self.m(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "gU8miKOOs-ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss(target, pred, criterion, metrics):\n",
        "    '''\n",
        "    TODO: THINK ABOUT NICE LOSS AND ALSO WEIGHTS\n",
        "    '''\n",
        "    if criterion == \"CEL\":\n",
        "        loss = nn.CrossEntropyLoss()\n",
        "    elif criterion == \"wCEL\":\n",
        "        loss = nn.CrossEntropyLoss() # TODO\n",
        "    else:\n",
        "        loss = nn.CrossEntropyLoss()\n",
        " \n",
        "    loss = loss(target, pred.long())\n",
        "    \"\"\"if metrics is not None:\n",
        "        metrics['loss'] += loss.data.cpu().numpy() * target.size(0) # TODO probably add f1 stuff\"\"\"\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "7rvfGN4GkXB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloaders, use_cuda, optimizer, num_epochs, checkpoint_path_model, loss_criterion: str,\n",
        "                trained_epochs: int = 0):\n",
        "    best_loss = 1e10\n",
        "    total_acc = {key: [] for key in ['train', 'val']}\n",
        "    total_loss = {key: [] for key in ['train', 'val']}\n",
        "\n",
        "    # iterate over all epochs\n",
        "    for epoch in range(trained_epochs, num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        since = time.time()\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            metrics = defaultdict(float)\n",
        "            epoch_samples = 0\n",
        "\n",
        "            for dic in tqdm(dataloaders[phase], total=len(dataloaders[phase])):\n",
        "                inputs, labels = dic['image'], dic['mask']\n",
        "\n",
        "                if use_cuda:\n",
        "                    inputs = inputs.to('cuda', dtype=torch.float)  # [batch_size, in_channels, H, W]\n",
        "                    labels = labels.to('cuda', dtype=torch.long)\n",
        "\n",
        "                optimizer.zero_grad()  # zero the parameter gradients\n",
        "\n",
        "                epoch_accuracy = 0\n",
        "                epoch_loss = 0\n",
        "                # forward pass: compute prediction and the loss btw prediction and true label\n",
        "                # track history only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "\n",
        "                    # output is probability [batch size, n_classes, H, W], target is class [batch size, H, W]\n",
        "                    # TODO: decide on loss!! (dummy function here)\n",
        "                    loss = calc_loss(outputs, labels, loss_criterion, metrics)\n",
        "\n",
        "                    # backward + optimize only if in training phase (no need for torch.no_grad in this training pass)\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                    epoch_loss += loss\n",
        "\n",
        "                # statistics\n",
        "                epoch_samples += inputs.size(0)\n",
        "\n",
        "                acc = ((outputs.argmax(dim=1) == labels).float().mean())\n",
        "                epoch_accuracy += acc / len(dataloaders[phase])\n",
        "                epoch_loss += loss / len(dataloaders[phase])\n",
        "            total_acc[phase].append(epoch_accuracy)\n",
        "            total_loss[phase].append(epoch_loss)\n",
        "\n",
        "            epoch_loss = loss / epoch_samples\n",
        "            print(\"epoch_loss = \", epoch_loss)\n",
        "\n",
        "            # save the model weights in validation phase \n",
        "            if phase == 'val':\n",
        "                if epoch_loss < best_loss:\n",
        "                    print(f\"saving best model to {checkpoint_path_model}\")\n",
        "                    best_loss = epoch_loss\n",
        "                    torch.save(model.state_dict(), checkpoint_path_model)\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    print('Best val loss: {:4f}'.format(best_loss))\n",
        "\n",
        "    plt.plot(total_loss['train'], color='blue')\n",
        "    plt.plot(total_loss['val'], color='orange')\n",
        "    plt.title(\"Loss\")\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['train_loss', 'valid_loss'])\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(total_acc['train'], color='blue')\n",
        "    plt.plot(total_acc['val'], color='orange')\n",
        "    plt.title(\"Accuracy\")\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.legend(['train_acc', 'val_acc'])\n",
        "    plt.show()\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(torch.load(checkpoint_path_model))\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "qs9uL-5Wsdgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_project_root() -> Path:\n",
        "    \"\"\" return path to the project root\"\"\"\n",
        "    return Path(__file__).parent\n",
        "\n",
        "\n",
        "def test(model, test_loader, use_cuda: bool, loss_criterion=None, n_classes = 5):\n",
        "    \"\"\"\n",
        "    Compute test metrics on test data set \n",
        "\n",
        "    @param model: -- the neural network\n",
        "    @param: use_cuda: -- true if GPU should be used\n",
        "    @param: loss_fun: -- the used loss function from calc_loss\n",
        "    @param: test_loader: -- test data dataloader\n",
        "    @param: test_batch_size: -- used batch size\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    labels = np.arange(n_classes)\n",
        "    conf_matrix = np.zeros((n_classes, n_classes))\n",
        "\n",
        "    # initialize all variables \n",
        "    num_correct = 0\n",
        "    num_pixels = 0\n",
        "    all_images = []\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "    test_losses = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        acc = 0\n",
        "        pre = 0\n",
        "        recall = 0\n",
        "        f1 = 0\n",
        "        for batch_index, dic in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "            images, labels = dic['image'], dic['mask']\n",
        "\n",
        "            all_images.extend(images.cpu())\n",
        "            all_labels.extend(labels.cpu())\n",
        "\n",
        "            if use_cuda:\n",
        "                images = images.to('cuda', dtype=torch.float)\n",
        "                labels = labels.to('cuda', dtype=torch.float)\n",
        "\n",
        "            # run network\n",
        "            prediction = model(images)  # torch.Size([batch_size, n_classes, h, w])\n",
        "\n",
        "            # compute and save loss\n",
        "            test_loss = calc_loss(prediction, labels.long(), criterion=loss_criterion)\n",
        "            test_losses.extend(test_loss.cpu().numpy().reshape(-1))\n",
        "\n",
        "            # take argmax to get class \n",
        "            final_prediction = torch.argmax(prediction.softmax(dim=1), dim=1)  # torch.Size([batch_size, h, w])\n",
        "\n",
        "            for j in range(len(labels)):\n",
        "                true_label = labels[j].cpu().detach().numpy().flatten()\n",
        "                pred_label = final_prediction[j].cpu().detach().numpy().flatten()\n",
        "                conf_matrix += confusion_matrix(true_label, pred_label,\n",
        "                                                labels=labels)  # TODO: maybe use to compute IoU (Intersection over Union)\n",
        "\n",
        "            all_predictions.extend(final_prediction.cpu())\n",
        "\n",
        "            # Compute number of correct predictions \n",
        "            num_correct += (final_prediction == labels).sum()\n",
        "            num_pixels += torch.numel(final_prediction)\n",
        "\n",
        "            #   calculate accuracy\n",
        "            acc += accuracy_score(true_label, pred_label) / len(test_loader)\n",
        "            #   calculate precision\n",
        "            pre += precision_score(true_label, pred_label, average='macro', zero_division=1) / len(test_loader)\n",
        "            #   calculate recall\n",
        "            recall += recall_score(true_label, pred_label, average='macro', zero_division=1) / len(test_loader)\n",
        "            #   calculate F1 score\n",
        "            f1 += f1_score(true_label, pred_label, average='macro') / len(test_loader)\n",
        "    print('Loss of best validation batch:', np.min(test_losses))\n",
        "\n",
        "    losses_per_instance = pd.DataFrame(data={'loss': test_losses})\n",
        "\n",
        "    # print metrics\n",
        "    print(\"Mean Loss:\", np.mean(test_losses), \"\\nMean Acc:\", acc, \"\\nMean Macro Precision:\", pre,\n",
        "          \"\\nMean Macro Recall:\", recall,\n",
        "          \"\\nMean Macro F1 Score:\", f1)\n",
        "\n",
        "    # plot confusion matrix\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(conf_matrix)\n",
        "    # We want to show all ticks...\n",
        "    ax.set_xticks(np.arange(n_classes))\n",
        "    ax.set_yticks(np.arange(n_classes))\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    test_accuracy = (num_correct / num_pixels * 100).cpu().numpy()\n",
        "    print(f\"Got {num_correct}/{num_pixels} with acc {test_accuracy}\")\n",
        "\n",
        "\n",
        "def test_model(test_loader, criterion):\n",
        "    best_path = 'best_unet.pth'\n",
        "    model = torch.load(best_path)\n",
        "\n",
        "    # evaluate on test set\n",
        "    model = model.eval()\n",
        "\n",
        "    test_loss_arr = []\n",
        "    with torch.no_grad():\n",
        "        epoch_test_loss = 0\n",
        "        acc = 0\n",
        "        pre = 0\n",
        "        recall = 0\n",
        "        f1 = 0\n",
        "        conf_matrix = np.zeros((5, 5))\n",
        "        #   iterate over test batches\n",
        "        for loaded_data in test_loader:\n",
        "            input_data, label = loaded_data\n",
        "            input_data = input_data.to('cuda', dtype=torch.float32)\n",
        "            label = label.to('cuda', dtype=torch.long)\n",
        "\n",
        "            test_output = model(input_data.float())\n",
        "            test_loss = criterion(test_output, label)\n",
        "\n",
        "            epoch_test_loss += test_loss / len(test_loader)\n",
        "            test_output = (test_output.argmax(dim=1)).long()\n",
        "            label = np.array(label.cpu())\n",
        "            test_output = np.array(test_output.cpu())\n",
        "            #   get confusion matrix\n",
        "            if (confusion_matrix(label, test_output).shape == (5, 5)):\n",
        "                conf_matrix += confusion_matrix(label, test_output) / len(test_loader)\n",
        "            #         conf_matrix.append(confusion_matrix(label, test_output))\n",
        "            #   calculate accuracy\n",
        "            acc += accuracy_score(label, test_output) / len(test_loader)\n",
        "            #   calculate precision\n",
        "            pre += precision_score(label, test_output, average='macro', zero_division=1) / len(test_loader)\n",
        "            #   calculate recall\n",
        "            recall += recall_score(label, test_output, average='macro', zero_division=1) / len(test_loader)\n",
        "            #   calculate F1 score\n",
        "            f1 += f1_score(label, test_output, average='macro') / len(test_loader)\n",
        "\n",
        "    test_loss_arr.append(epoch_test_loss)\n",
        "    test_loss_arr = np.array(test_loss_arr, dtype='float')\n",
        "    losses = np.mean(test_loss_arr)\n",
        "\n",
        "    # print metrics\n",
        "    print(\"Mean Loss:\", losses, \"\\nMean Acc:\", acc, \"\\nMean Macro Precision:\", pre, \"\\nMean Macro Recall:\", recall,\n",
        "          \"\\nMean Macro F1 Score:\", f1)\n",
        "\n",
        "    # plot confusion matrix\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(conf_matrix)\n",
        "    # We want to show all ticks...\n",
        "    ax.set_xticks(np.arange(5))\n",
        "    ax.set_yticks(np.arange(5))\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "SYfk4sPwkBO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from matplotlib.transforms import Transform\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from skimage.io import imread\n",
        "import glob\n",
        "\n",
        "class CityData(Dataset):\n",
        "\n",
        "    def __init__(self, train_test_path, transforms = None):\n",
        "        \"\"\"\n",
        "        train_test_path -- path to either \"train\", \"val\", or \"test\" containing subfolders 'images' and 'masks' where the patched data lies, e.g. ../patches/train\n",
        "        transform -- transform (from torchvision.transforms) to be applied to the data\n",
        "\n",
        "        Usage: citydata = CityData(train_test_path)\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Define Dataset \n",
        "        self.patch_imgs_path = sorted(glob.glob(train_test_path + 'images/*'))\n",
        "        self.patch_masks_path = sorted(glob.glob(train_test_path + 'masks/*'))\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        return the number of total samples contained in the dataset\n",
        "        \"\"\"\n",
        "        return len(self.patch_imgs_path)\n",
        "\n",
        "    def __getitem__(self, idx): \n",
        "        \"\"\" \n",
        "        Return the examples at index [idx]. The example is a dict with keys \n",
        "        - 'images' value: Tensor for an RGB image of shape \n",
        "        - 'mask' value: ground truth labels 0,..., n_classes of shape\n",
        "        - 'img_idx' value: index of sample\n",
        "        \"\"\"\n",
        "\n",
        "        image = np.load(self.patch_imgs_path[idx])\n",
        "        mask = np.load(self.patch_masks_path[idx])\n",
        "\n",
        "        \"\"\"image = []\n",
        "        for image_path in glob.glob(f\"{self.patch_imgs_path}/*.npy\"):\n",
        "          image.append(np.load(image_path))\n",
        "\n",
        "        mask = []\n",
        "        for image_path in glob.glob(f\"{self.patch_masks_path}/*.npy\"):\n",
        "          mask.append(np.load(image_path))\"\"\"\n",
        "        \n",
        "        # To tensor \n",
        "        #image = torch.from_numpy(image) \n",
        "        #mask = torch.from_numpy(mask)    \n",
        "\n",
        "        #preprocessed image, for input into NN\n",
        "        sample = {'image':image, 'mask':mask, 'img_idx':idx}\n",
        "\n",
        "        if self.transforms:\n",
        "            sample = self.transforms(sample)\n",
        "\n",
        "        return sample"
      ],
      "metadata": {
        "id": "XBbZJ6SFn75j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_dataset = np.load(\"/content/drive/MyDrive/train_set.npy\", allow_pickle=True)\n",
        "test_dataset = np.load(\"/content/drive/MyDrive/test_set.npy\", allow_pickle=True)\n",
        "val_dataset = np.load(\"/content/drive/MyDrive/val_set.npy\", allow_pickle=True)"
      ],
      "metadata": {
        "id": "KhtcSWXLxPg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"train_set = CityData(os.path.join(\"/content/drive/MyDrive/patches_new/patches/\", 'train/'))\n",
        "val_set = CityData(\"/content/drive/MyDrive/patches_new/patches/val/\") \n",
        "test_set = CityData(os.path.join(\"/content/drive/MyDrive/patches_new/patches/\", 'test/'))\n",
        "\n",
        "train_dataset = []\n",
        "for idx in range(train_set.__len__()):\n",
        "    train_dataset.append(train_set.__getitem__(idx))\n",
        "\n",
        "val_dataset = []\n",
        "for idx in range(val_set.__len__()):\n",
        "    val_dataset.append(val_set.__getitem__(idx))\n",
        "\n",
        "test_dataset = []\n",
        "for idx in range(test_set.__len__()):\n",
        "    test_dataset.append(test_set.__getitem__(idx))\"\"\""
      ],
      "metadata": {
        "id": "iiesz1-Quy8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(test_dataset.size):\n",
        "    test_dataset[idx]['mask'] = np.int32(test_dataset[idx]['mask'])"
      ],
      "metadata": {
        "id": "rK0Evijjz6ZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(val_dataset.size):\n",
        "    val_dataset[idx]['mask'] = np.int32(val_dataset[idx]['mask'])"
      ],
      "metadata": {
        "id": "cUf_TsJH2N6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_loaders = get_dataloaders(test_dataset, val_dataset, batch_size=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMXm6PMn7Myf",
        "outputId": "07d7fc89-d418-4bb5-dfb0-2b79875fce73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(data_loaders['train'].dataset.size):\n",
        "    data_loaders['train'].dataset[idx]['image'] = np.reshape(data_loaders['train'].dataset[idx]['image'], (4, 128, 128))"
      ],
      "metadata": {
        "id": "YTRYTvOjvDvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(data_loaders['val'].dataset.size):\n",
        "    data_loaders['val'].dataset[idx]['image'] = np.reshape(data_loaders['val'].dataset[idx]['image'], (4, 128, 128))"
      ],
      "metadata": {
        "id": "S0A6swb26RQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick your hyper parameters\n",
        "epoch_count = 3\n",
        "train_val_batch = 64\n",
        "test_batch = 64\n",
        "learning_rate = 0.01\n",
        "weight_decay = 0.001\n",
        "\n",
        "# initialize your network\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = UNet()\n",
        "model = model.to(device, dtype=torch.float)\n",
        "#summary(model, input_size=(4, 64, 64))\n",
        "\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "use_cuda = torch.cuda.is_available()\n",
        "trained_model = train_model(model=model, dataloaders=data_loaders, use_cuda=use_cuda, optimizer=optimizer,\n",
        "                            num_epochs=epoch_count, loss_criterion=\"CEL\", checkpoint_path_model=\"best_unet.pth\")"
      ],
      "metadata": {
        "id": "kcwVdiQpj5fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = get_test_dataloaders(test_dataset=test_dataset, batch_size=test_batch)\n",
        "\n",
        "test(model=trained_model, use_cuda=True, test_loader=test_loader, n_classes=5, loss_criterion=\"CEL\")"
      ],
      "metadata": {
        "id": "BKYIohDjRGFP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}