{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1yirBwNnP-IEkZ4KO-8LdtJLqNGPZcDjc",
      "authorship_tag": "ABX9TyPROKUnM13oJxAWvXUEylqr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cemdaloglu/AML_project/blob/main/aml_proj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import random_split\n",
        "import time\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, accuracy_score\n",
        "from pathlib import Path\n",
        "import time\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "5f8bNThWsuMU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fMZhLpXVsBqQ"
      },
      "outputs": [],
      "source": [
        "def get_dataloaders(train_dataset, val_dataset, dataloader_workers: int = 3, batch_size: int = 8):\n",
        "    \"\"\"\n",
        "    Get Dataloaders for the given dataset.\n",
        "    \n",
        "    @param dataset The dataset to wrap into a Dataloader\n",
        "    @param dataloader_workers How many workers to give each Dataloader.\n",
        "    @param batch_size Batch Size\n",
        "    \"\"\"\n",
        "\n",
        "    kwargs = {'pin_memory': True, 'num_workers': dataloader_workers}\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "        **kwargs\n",
        "    )\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        drop_last=True,\n",
        "        shuffle=True,\n",
        "        **kwargs\n",
        "    )\n",
        "    return {\n",
        "        'train': train_loader,\n",
        "        'val': val_loader\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_test_dataloaders(test_dataset, dataloader_workers: int = 3, batch_size: int = 8):\n",
        "    \"\"\"\n",
        "    Get Dataloaders for the given dataset.\n",
        "\n",
        "    @param test_dataset The dataset to wrap into a Dataloader\n",
        "    @param dataloader_workers How many workers to give each Dataloader.\n",
        "    @param batch_size Batch Size\n",
        "    \"\"\"\n",
        "\n",
        "    kwargs = {'pin_memory': True, 'num_workers': dataloader_workers}\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "        **kwargs\n",
        "    )\n",
        "    return test_loader"
      ],
      "metadata": {
        "id": "FuCon8m2j0Vz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding='same'),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding='same'),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)"
      ],
      "metadata": {
        "id": "UabXpNVBs0OR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DownBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DownBlock, self).__init__()\n",
        "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
        "        self.down_sample = nn.MaxPool2d(2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_out = self.double_conv(x)\n",
        "        down_out = self.down_sample(skip_out)\n",
        "        return down_out, skip_out"
      ],
      "metadata": {
        "id": "IR5I_govs6LO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UpBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UpBlock, self).__init__()\n",
        "        self.up_sample = nn.ConvTranspose2d(in_channels - out_channels, in_channels - out_channels, kernel_size=2,\n",
        "                                            stride=2)\n",
        "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, down_input, skip_input):\n",
        "        x = self.up_sample(down_input)\n",
        "        x = torch.cat([x, skip_input], dim=1)\n",
        "        return self.double_conv(x)"
      ],
      "metadata": {
        "id": "z66sw3dWs8Oc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, out_classes=6):\n",
        "        super(UNet, self).__init__()\n",
        "        # Downsampling Path\n",
        "        self.down_conv1 = DownBlock(4, 64)\n",
        "        self.down_conv2 = DownBlock(64, 128)\n",
        "        self.down_conv3 = DownBlock(128, 256)\n",
        "        self.down_conv4 = DownBlock(256, 512)\n",
        "        # Bottleneck\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.double_conv = DoubleConv(512, 1024)\n",
        "        # Upsampling Path\n",
        "        self.up_conv4 = UpBlock(512 + 1024, 512)\n",
        "        self.up_conv3 = UpBlock(256 + 512, 256)\n",
        "        self.up_conv2 = UpBlock(128 + 256, 128)\n",
        "        self.up_conv1 = UpBlock(128 + 64, 64)\n",
        "        # Final Convolution\n",
        "        self.conv_last = nn.Conv2d(64, out_classes, kernel_size=1)\n",
        "        self.m = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, skip1_out = self.down_conv1(x)\n",
        "        x, skip2_out = self.down_conv2(x)\n",
        "        x, skip3_out = self.down_conv3(x)\n",
        "        x, skip4_out = self.down_conv4(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.double_conv(x)\n",
        "        x = self.up_conv4(x, skip4_out)\n",
        "        x = self.up_conv3(x, skip3_out)\n",
        "        x = self.up_conv2(x, skip2_out)\n",
        "        x = self.up_conv1(x, skip1_out)\n",
        "        x = self.conv_last(x)\n",
        "        x = self.m(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "gU8miKOOs-ae"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss(target, pred, criterion, metrics):\n",
        "    '''\n",
        "    TODO: THINK ABOUT NICE LOSS AND ALSO WEIGHTS\n",
        "    '''\n",
        "    if criterion == \"CEL\":\n",
        "        loss = nn.CrossEntropyLoss()\n",
        "    elif criterion == \"wCEL\":\n",
        "        loss = nn.CrossEntropyLoss() # TODO\n",
        "    else:\n",
        "        loss = nn.CrossEntropyLoss()\n",
        " \n",
        "    loss = loss(target, pred.long())\n",
        "    \"\"\"if metrics is not None:\n",
        "        metrics['loss'] += loss.data.cpu().numpy() * target.size(0) # TODO probably add f1 stuff\"\"\"\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "7rvfGN4GkXB7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloaders, use_cuda, optimizer, num_epochs, checkpoint_path_model, loss_criterion: str,\n",
        "                trained_epochs: int = 0):\n",
        "    best_loss = 1e10\n",
        "    total_acc = {key: [] for key in ['train', 'val']}\n",
        "    total_loss = {key: [] for key in ['train', 'val']}\n",
        "\n",
        "    # iterate over all epochs\n",
        "    for epoch in range(trained_epochs, num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        since = time.time()\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            metrics = defaultdict(float)\n",
        "            epoch_samples = 0\n",
        "\n",
        "            for dic in tqdm(dataloaders[phase], total=len(dataloaders[phase])):\n",
        "                inputs, labels = dic['image'], dic['mask']\n",
        "\n",
        "                if use_cuda:\n",
        "                    inputs = inputs.to('cuda', dtype=torch.float)  # [batch_size, in_channels, H, W]\n",
        "                    labels = labels.to('cuda', dtype=torch.long)\n",
        "\n",
        "                optimizer.zero_grad()  # zero the parameter gradients\n",
        "\n",
        "                epoch_accuracy = 0\n",
        "                epoch_loss = 0\n",
        "                # forward pass: compute prediction and the loss btw prediction and true label\n",
        "                # track history only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "\n",
        "                    # output is probability [batch size, n_classes, H, W], target is class [batch size, H, W]\n",
        "                    # TODO: decide on loss!! (dummy function here)\n",
        "                    loss = calc_loss(outputs, labels, loss_criterion, metrics)\n",
        "\n",
        "                    # backward + optimize only if in training phase (no need for torch.no_grad in this training pass)\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                    epoch_loss += loss\n",
        "\n",
        "                # statistics\n",
        "                epoch_samples += inputs.size(0)\n",
        "\n",
        "                acc = ((outputs.argmax(dim=1) == labels).float().mean())\n",
        "                epoch_accuracy += acc / len(dataloaders[phase])\n",
        "                epoch_loss += loss / len(dataloaders[phase])\n",
        "            print('Epoch : {}, train accuracy : {}, train loss : {}'.format(epoch+1, epoch_accuracy, epoch_loss))\n",
        "            total_acc[phase].append(epoch_accuracy)\n",
        "            total_loss[phase].append(epoch_loss)\n",
        "\n",
        "            epoch_loss = loss / epoch_samples\n",
        "            print(\"epoch_loss = \", epoch_loss)\n",
        "\n",
        "            # save the model weights in validation phase \n",
        "            if phase == 'val':\n",
        "                if epoch_loss < best_loss:\n",
        "                    print(f\"saving best model to {checkpoint_path_model}\")\n",
        "                    best_loss = epoch_loss\n",
        "                    torch.save(model.state_dict(), checkpoint_path_model)\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    print('Best val loss: {:4f}'.format(best_loss))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(torch.load(checkpoint_path_model))\n",
        "    return model, total_loss, total_acc\n"
      ],
      "metadata": {
        "id": "qs9uL-5Wsdgt"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training(total_loss, total_acc):\n",
        "    total_loss_train = []\n",
        "    for idx in range(len(total_loss['train'])):\n",
        "        total_loss_train.append(total_loss['train'][idx].detach().cpu().numpy())\n",
        "\n",
        "    total_loss_val = []\n",
        "    for idx in range(len(total_loss['val'])):\n",
        "        total_loss_val.append(total_loss['val'][idx].detach().cpu().numpy())\n",
        "\n",
        "    total_acc_train = []\n",
        "    for idx in range(len(total_acc['train'])):\n",
        "        total_acc_train.append(total_acc['train'][idx].detach().cpu().numpy())\n",
        "\n",
        "    total_acc_val = []\n",
        "    for idx in range(len(total_acc['val'])):\n",
        "        total_acc_val.append(total_acc['val'][idx].detach().cpu().numpy())\n",
        "\n",
        "    plt.plot(total_loss_train, color='blue')\n",
        "    plt.plot(total_loss_val, color='orange')\n",
        "    plt.title(\"Loss\")\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['train_loss', 'valid_loss'])\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(total_acc_train, color='blue')\n",
        "    plt.plot(total_acc_val, color='orange')\n",
        "    plt.title(\"Accuracy\")\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.legend(['train_acc', 'val_acc'])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "U_tZ_Vb8nJ6S"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_project_root() -> Path:\n",
        "    \"\"\" return path to the project root\"\"\"\n",
        "    return Path(__file__).parent\n",
        "\n",
        "\n",
        "def test(model, test_loader, use_cuda: bool, loss_criterion=None, n_classes = 5):\n",
        "    \"\"\"\n",
        "    Compute test metrics on test data set \n",
        "\n",
        "    @param model: -- the neural network\n",
        "    @param: use_cuda: -- true if GPU should be used\n",
        "    @param: loss_fun: -- the used loss function from calc_loss\n",
        "    @param: test_loader: -- test data dataloader\n",
        "    @param: test_batch_size: -- used batch size\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    labels = np.arange(n_classes)\n",
        "    conf_matrix = np.zeros((n_classes, n_classes))\n",
        "\n",
        "    # initialize all variables \n",
        "    num_correct = 0\n",
        "    num_pixels = 0\n",
        "    all_images = []\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "    test_losses = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        acc = 0\n",
        "        pre = 0\n",
        "        recall = 0\n",
        "        f1 = 0\n",
        "        for batch_index, dic in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "            images, labels = dic['image'], dic['mask']\n",
        "\n",
        "            all_images.extend(images.cpu())\n",
        "            all_labels.extend(labels.cpu())\n",
        "\n",
        "            if use_cuda:\n",
        "                images = images.to('cuda', dtype=torch.float)\n",
        "                labels = labels.to('cuda', dtype=torch.float)\n",
        "\n",
        "            # run network\n",
        "            prediction = model(images)  # torch.Size([batch_size, n_classes, h, w])\n",
        "\n",
        "            # compute and save loss\n",
        "            test_loss = calc_loss(prediction, labels.long(), criterion=loss_criterion, metrics = defaultdict(float))\n",
        "            test_losses.extend(test_loss.cpu().numpy().reshape(-1))\n",
        "\n",
        "            # take argmax to get class \n",
        "            final_prediction = torch.argmax(prediction.softmax(dim=1), dim=1)  # torch.Size([batch_size, h, w])\n",
        "\n",
        "            for j in range(len(labels)):\n",
        "                true_label = labels[j].cpu().detach().numpy().flatten()\n",
        "                pred_label = final_prediction[j].cpu().detach().numpy().flatten()\n",
        "                conf_matrix += confusion_matrix(true_label, pred_label,\n",
        "                                                labels=labels.cpu().detach().numpy())  # TODO: maybe use to compute IoU (Intersection over Union)\n",
        "\n",
        "            all_predictions.extend(final_prediction.cpu())\n",
        "\n",
        "            # Compute number of correct predictions \n",
        "            num_correct += (final_prediction == labels).sum()\n",
        "            num_pixels += torch.numel(final_prediction)\n",
        "\n",
        "            #   calculate accuracy\n",
        "            acc += accuracy_score(true_label, pred_label) / len(test_loader)\n",
        "            #   calculate precision\n",
        "            pre += precision_score(true_label, pred_label, average='macro', zero_division=1) / len(test_loader)\n",
        "            #   calculate recall\n",
        "            recall += recall_score(true_label, pred_label, average='macro', zero_division=1) / len(test_loader)\n",
        "            #   calculate F1 score\n",
        "            f1 += f1_score(true_label, pred_label, average='macro') / len(test_loader)\n",
        "    print('Loss of best validation batch:', np.min(test_losses))\n",
        "\n",
        "    losses_per_instance = pd.DataFrame(data={'loss': test_losses})\n",
        "\n",
        "    # print metrics\n",
        "    print(\"Mean Loss:\", np.mean(test_losses), \"\\nMean Acc:\", acc, \"\\nMean Macro Precision:\", pre,\n",
        "          \"\\nMean Macro Recall:\", recall,\n",
        "          \"\\nMean Macro F1 Score:\", f1)\n",
        "\n",
        "    # plot confusion matrix\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(conf_matrix)\n",
        "    # We want to show all ticks...\n",
        "    ax.set_xticks(np.arange(n_classes))\n",
        "    ax.set_yticks(np.arange(n_classes))\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    test_accuracy = (num_correct / num_pixels * 100).cpu().numpy()\n",
        "    print(f\"Got {num_correct}/{num_pixels} with acc {test_accuracy}\")\n",
        "\n",
        "\n",
        "def test_model(test_loader, criterion):\n",
        "    best_path = 'best_unet.pth'\n",
        "    model = torch.load(best_path)\n",
        "\n",
        "    # evaluate on test set\n",
        "    model = model.eval()\n",
        "\n",
        "    test_loss_arr = []\n",
        "    with torch.no_grad():\n",
        "        epoch_test_loss = 0\n",
        "        acc = 0\n",
        "        pre = 0\n",
        "        recall = 0\n",
        "        f1 = 0\n",
        "        conf_matrix = np.zeros((5, 5))\n",
        "        #   iterate over test batches\n",
        "        for loaded_data in test_loader:\n",
        "            input_data, label = loaded_data\n",
        "            input_data = input_data.to('cuda', dtype=torch.float32)\n",
        "            label = label.to('cuda', dtype=torch.long)\n",
        "\n",
        "            test_output = model(input_data.float())\n",
        "            test_loss = criterion(test_output, label)\n",
        "\n",
        "            epoch_test_loss += test_loss / len(test_loader)\n",
        "            test_output = (test_output.argmax(dim=1)).long()\n",
        "            label = np.array(label.cpu())\n",
        "            test_output = np.array(test_output.cpu())\n",
        "            #   get confusion matrix\n",
        "            if (confusion_matrix(label, test_output).shape == (5, 5)):\n",
        "                conf_matrix += confusion_matrix(label, test_output) / len(test_loader)\n",
        "            #         conf_matrix.append(confusion_matrix(label, test_output))\n",
        "            #   calculate accuracy\n",
        "            acc += accuracy_score(label, test_output) / len(test_loader)\n",
        "            #   calculate precision\n",
        "            pre += precision_score(label, test_output, average='macro', zero_division=1) / len(test_loader)\n",
        "            #   calculate recall\n",
        "            recall += recall_score(label, test_output, average='macro', zero_division=1) / len(test_loader)\n",
        "            #   calculate F1 score\n",
        "            f1 += f1_score(label, test_output, average='macro') / len(test_loader)\n",
        "\n",
        "    test_loss_arr.append(epoch_test_loss)\n",
        "    test_loss_arr = np.array(test_loss_arr, dtype='float')\n",
        "    losses = np.mean(test_loss_arr)\n",
        "\n",
        "    # print metrics\n",
        "    print(\"Mean Loss:\", losses, \"\\nMean Acc:\", acc, \"\\nMean Macro Precision:\", pre, \"\\nMean Macro Recall:\", recall,\n",
        "          \"\\nMean Macro F1 Score:\", f1)\n",
        "\n",
        "    # plot confusion matrix\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(conf_matrix)\n",
        "    # We want to show all ticks...\n",
        "    ax.set_xticks(np.arange(5))\n",
        "    ax.set_yticks(np.arange(5))\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "SYfk4sPwkBO0"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from matplotlib.transforms import Transform\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from skimage.io import imread\n",
        "import glob\n",
        "\n",
        "class CityData(Dataset):\n",
        "\n",
        "    def __init__(self, train_test_path, transforms = None):\n",
        "        \"\"\"\n",
        "        train_test_path -- path to either \"train\", \"val\", or \"test\" containing subfolders 'images' and 'masks' where the patched data lies, e.g. ../patches/train\n",
        "        transform -- transform (from torchvision.transforms) to be applied to the data\n",
        "\n",
        "        Usage: citydata = CityData(train_test_path)\n",
        "        \"\"\"\n",
        "        self.transforms = transforms\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Define Dataset \n",
        "        self.patch_imgs_path = sorted(glob.glob(train_test_path + 'images/*'))\n",
        "        self.patch_masks_path = sorted(glob.glob(train_test_path + 'masks/*'))\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        return the number of total samples contained in the dataset\n",
        "        \"\"\"\n",
        "        return len(self.patch_imgs_path)\n",
        "\n",
        "    def __getitem__(self, idx): \n",
        "        \"\"\" \n",
        "        Return the examples at index [idx]. The example is a dict with keys \n",
        "        - 'images' value: Tensor for an RGB image of shape \n",
        "        - 'mask' value: ground truth labels 0,..., n_classes of shape\n",
        "        - 'img_idx' value: index of sample\n",
        "        \"\"\"\n",
        "\n",
        "        image = np.load(self.patch_imgs_path[idx])\n",
        "        mask = np.load(self.patch_masks_path[idx])\n",
        "\n",
        "        \"\"\"image = []\n",
        "        for image_path in glob.glob(f\"{self.patch_imgs_path}/*.npy\"):\n",
        "          image.append(np.load(image_path))\n",
        "\n",
        "        mask = []\n",
        "        for image_path in glob.glob(f\"{self.patch_masks_path}/*.npy\"):\n",
        "          mask.append(np.load(image_path))\"\"\"\n",
        "        \n",
        "        # To tensor \n",
        "        #image = torch.from_numpy(image) \n",
        "        #mask = torch.from_numpy(mask)    \n",
        "\n",
        "        #preprocessed image, for input into NN\n",
        "        sample = {'image':image, 'mask':mask, 'img_idx':idx}\n",
        "\n",
        "        if self.transforms:\n",
        "            sample = self.transforms(sample)\n",
        "\n",
        "        return sample"
      ],
      "metadata": {
        "id": "XBbZJ6SFn75j"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_dataset = np.load(\"/content/drive/MyDrive/train_set.npy\", allow_pickle=True)\n",
        "test_dataset = np.load(\"/content/drive/MyDrive/test_set.npy\", allow_pickle=True)\n",
        "val_dataset = np.load(\"/content/drive/MyDrive/val_set.npy\", allow_pickle=True)"
      ],
      "metadata": {
        "id": "KhtcSWXLxPg-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"train_set = CityData(os.path.join(\"/content/drive/MyDrive/patches_new/patches/\", 'train/'))\n",
        "val_set = CityData(\"/content/drive/MyDrive/patches_new/patches/val/\") \n",
        "test_set = CityData(os.path.join(\"/content/drive/MyDrive/patches_new/patches/\", 'test/'))\n",
        "\n",
        "train_dataset = []\n",
        "for idx in range(train_set.__len__()):\n",
        "    train_dataset.append(train_set.__getitem__(idx))\n",
        "\n",
        "val_dataset = []\n",
        "for idx in range(val_set.__len__()):\n",
        "    val_dataset.append(val_set.__getitem__(idx))\n",
        "\n",
        "test_dataset = []\n",
        "for idx in range(test_set.__len__()):\n",
        "    test_dataset.append(test_set.__getitem__(idx))\"\"\""
      ],
      "metadata": {
        "id": "iiesz1-Quy8w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "13744a42-4c43-4647-e47a-7898d26644d5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'train_set = CityData(os.path.join(\"/content/drive/MyDrive/patches_new/patches/\", \\'train/\\'))\\nval_set = CityData(\"/content/drive/MyDrive/patches_new/patches/val/\") \\ntest_set = CityData(os.path.join(\"/content/drive/MyDrive/patches_new/patches/\", \\'test/\\'))\\n\\ntrain_dataset = []\\nfor idx in range(train_set.__len__()):\\n    train_dataset.append(train_set.__getitem__(idx))\\n\\nval_dataset = []\\nfor idx in range(val_set.__len__()):\\n    val_dataset.append(val_set.__getitem__(idx))\\n\\ntest_dataset = []\\nfor idx in range(test_set.__len__()):\\n    test_dataset.append(test_set.__getitem__(idx))'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(test_dataset.size):\n",
        "    test_dataset[idx]['mask'] = np.int32(test_dataset[idx]['mask'])"
      ],
      "metadata": {
        "id": "rK0Evijjz6ZL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(val_dataset.size):\n",
        "    val_dataset[idx]['mask'] = np.int32(val_dataset[idx]['mask'])"
      ],
      "metadata": {
        "id": "cUf_TsJH2N6o"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_loaders = get_dataloaders(test_dataset, val_dataset, batch_size=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMXm6PMn7Myf",
        "outputId": "30743bc5-9641-4d68-a951-2b45f4252682"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(data_loaders['train'].dataset.size):\n",
        "    data_loaders['train'].dataset[idx]['image'] = np.reshape(data_loaders['train'].dataset[idx]['image'], (4, 128, 128))"
      ],
      "metadata": {
        "id": "YTRYTvOjvDvV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(data_loaders['val'].dataset.size):\n",
        "    data_loaders['val'].dataset[idx]['image'] = np.reshape(data_loaders['val'].dataset[idx]['image'], (4, 128, 128))"
      ],
      "metadata": {
        "id": "S0A6swb26RQc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick your hyper parameters\n",
        "epoch_count = 2\n",
        "train_val_batch = 16\n",
        "test_batch = 16\n",
        "learning_rate = 0.01\n",
        "weight_decay = 0.001\n",
        "\n",
        "# initialize your network\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = UNet()\n",
        "model = model.to(device, dtype=torch.float)\n",
        "#summary(model, input_size=(4, 64, 64))\n",
        "\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "use_cuda = torch.cuda.is_available()\n",
        "trained_model, total_loss, total_acc = train_model(model=model, dataloaders=data_loaders, use_cuda=use_cuda, optimizer=optimizer,\n",
        "                            num_epochs=epoch_count, loss_criterion=\"CEL\", checkpoint_path_model=\"best_unet.pth\")"
      ],
      "metadata": {
        "id": "kcwVdiQpj5fg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e0b17bf-bf60-4ab6-d008-954454c42c9a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/2\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/231 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 231/231 [00:58<00:00,  3.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1, train accuracy : 0.002746846294030547, train loss : 1.4140660762786865\n",
            "epoch_loss =  tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 159/159 [00:13<00:00, 11.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1, train accuracy : 0.004319820553064346, train loss : 1.367431640625\n",
            "epoch_loss =  tensor(0.0005, device='cuda:0')\n",
            "saving best model to best_unet.pth\n",
            "1m 12s\n",
            "Epoch 1/2\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 231/231 [00:57<00:00,  4.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 2, train accuracy : 0.0029055278282612562, train loss : 1.3790303468704224\n",
            "epoch_loss =  tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 159/159 [00:13<00:00, 11.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 2, train accuracy : 0.004420178476721048, train loss : 1.3555641174316406\n",
            "epoch_loss =  tensor(0.0005, device='cuda:0')\n",
            "saving best model to best_unet.pth\n",
            "1m 11s\n",
            "Best val loss: 0.000530\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training(total_loss, total_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "0xSfXYUCnfjJ",
        "outputId": "3653caf8-41ea-4b17-c4d0-73cc81e28308"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = get_test_dataloaders(test_dataset=test_dataset, batch_size=test_batch)\n",
        "\n",
        "test(model=trained_model, use_cuda=True, test_loader=test_loader, n_classes=5, loss_criterion=\"CEL\")"
      ],
      "metadata": {
        "id": "BKYIohDjRGFP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "9fc9b8ce-3e78-415d-a1f8-a75916de5b64"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "  0%|          | 0/231 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-27d4115ab704>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_test_dataloaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_criterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"CEL\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-50-48f906e87320>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, test_loader, use_cuda, loss_criterion, n_classes)\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mpred_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_prediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 conf_matrix += confusion_matrix(true_label, pred_label,\n\u001b[0;32m---> 57\u001b[0;31m                                                 labels=labels.cpu().detach().numpy())  # TODO: maybe use to compute IoU (Intersection over Union)\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mall_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    341\u001b[0m     )\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mneed_index_conversion\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0mlabel_to_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_to_ind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_labels\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_to_ind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_labels\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    341\u001b[0m     )\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mneed_index_conversion\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0mlabel_to_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_to_ind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_labels\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_to_ind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_labels\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
          ]
        }
      ]
    }
  ]
}